{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04cc3d60-386d-453b-b67c-d7fa773b77e2",
   "metadata": {},
   "source": [
    "# Save and load the `elicit` object\n",
    "\n",
    "## Save an unfitted `elicit` object (e.g., for sharing with collaborators)\n",
    "\n",
    "### Step 0: Load necessary libraries and functions/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca076e31-a765-40ec-8829-81c526f1ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import elicit as el\n",
    "\n",
    "from elicit.extras import utils\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# numeric, standardized predictor\n",
    "def std_predictor(N, quantiles):\n",
    "    X = tf.cast(np.arange(N), tf.float32)\n",
    "    X_std = (X-tf.reduce_mean(X))/tf.math.reduce_std(X)\n",
    "    X_sel = tfp.stats.percentile(X_std, quantiles)\n",
    "    return X_sel\n",
    "\n",
    "# implemented, generative model\n",
    "class ToyModel:\n",
    "    def __call__(self, prior_samples, design_matrix, **kwargs):\n",
    "        B = prior_samples.shape[0]\n",
    "        S = prior_samples.shape[1]\n",
    "\n",
    "        # preprocess shape of design matrix\n",
    "        X = tf.broadcast_to(design_matrix[None, None,:],\n",
    "                           (B,S,len(design_matrix)))\n",
    "        # linear predictor (= mu)\n",
    "        epred = tf.add(prior_samples[:, :, 0][:,:,None],\n",
    "                       tf.multiply(prior_samples[:, :, 1][:,:,None], X)\n",
    "                       )\n",
    "        # data-generating model\n",
    "        likelihood = tfd.Normal(\n",
    "            loc=epred, scale=tf.expand_dims(prior_samples[:, :, -1], -1)\n",
    "        )\n",
    "        # prior predictive distribution (=height)\n",
    "        ypred = likelihood.sample()\n",
    "        \n",
    "        # selected observations\n",
    "        y_X0, y_X1, y_X2 = (ypred[:,:,0], ypred[:,:,1], ypred[:,:,2])\n",
    "\n",
    "        return dict(\n",
    "            likelihood=likelihood,\n",
    "            ypred=ypred, epred=epred,\n",
    "            prior_samples=prior_samples,\n",
    "            y_X0=y_X0, y_X1=y_X1, y_X2=y_X2\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e52717-b3eb-4f80-b0ed-2d3f62558d55",
   "metadata": {},
   "source": [
    "### Step 1: Create the `elicit` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a67cce1-1a9c-4e0c-9aaa-1596ca67d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the generative model\n",
    "model=el.model(\n",
    "        obj=ToyModel,\n",
    "        design_matrix=std_predictor(N=200, quantiles=[25,50,75])\n",
    "        )\n",
    "\n",
    "# specify the model parameters and their prior distribution families\n",
    "parameters=[\n",
    "        el.parameter(\n",
    "            name=\"beta0\",\n",
    "            family=tfd.Normal,\n",
    "            hyperparams=dict(\n",
    "                loc=el.hyper(\"mu0\"),\n",
    "                scale=el.hyper(\"sigma0\", lower=0)\n",
    "                )\n",
    "        ),\n",
    "        el.parameter(\n",
    "            name=\"beta1\",\n",
    "            family=tfd.Normal,\n",
    "            hyperparams=dict(\n",
    "                loc=el.hyper(\"mu1\"),\n",
    "                scale=el.hyper(\"sigma1\", lower=0) # TODO specify error message\n",
    "                )\n",
    "        ),\n",
    "        el.parameter(\n",
    "            name=\"sigma\",\n",
    "            family=tfd.HalfNormal,\n",
    "            hyperparams=dict(\n",
    "                scale=el.hyper(\"sigma2\", lower=0)\n",
    "                )\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "# specify the target quantities and corresponding elicitation technique\n",
    "targets=[\n",
    "        el.target(\n",
    "            name=f\"y_X{i}\",\n",
    "            query=el.queries.quantiles((5, 25, 50, 75, 95)),\n",
    "            loss=el.losses.MMD2(kernel=\"energy\"),\n",
    "            weight=1.0\n",
    "        ) for i in range(3)\n",
    "    ]\n",
    "\n",
    "# use an oracle to simulate a ground truth for the expert data\n",
    "expert=el.expert.simulator(\n",
    "        ground_truth = {\n",
    "            \"beta0\": tfd.Normal(loc=5, scale=1),\n",
    "            \"beta1\": tfd.Normal(loc=2, scale=1),\n",
    "            \"sigma\": tfd.HalfNormal(scale=10.0),\n",
    "        },\n",
    "        num_samples = 10_000\n",
    "    )\n",
    "\n",
    "# specify the optimizer for gradient descent\n",
    "optimizer=el.optimizer(\n",
    "        optimizer=tf.keras.optimizers.Adam,\n",
    "        learning_rate=0.1,\n",
    "        clipnorm=1.0\n",
    "        )\n",
    "\n",
    "# define the trainer model with model name, used approach, seed, etc.\n",
    "trainer=el.trainer(\n",
    "        method=\"parametric_prior\",\n",
    "        name=\"toy0\",\n",
    "        seed=0,\n",
    "        epochs=4\n",
    "    )\n",
    "\n",
    "# specify the initialization distribution, used to draw the initial values \n",
    "# for the hyperparameters\n",
    "initializer=el.initializer(\n",
    "        method=\"sobol\",\n",
    "        loss_quantile=0,\n",
    "        iterations=8,\n",
    "        distribution=el.initialization.uniform(\n",
    "            radius=1,\n",
    "            mean=0\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e708020e-c445-4df5-ad04-1563e18cbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "elicit = el.Elicit(\n",
    "    model=model,\n",
    "    parameters=parameters,\n",
    "    targets=targets,\n",
    "    expert=expert,\n",
    "    optimizer=optimizer,\n",
    "    trainer=trainer,\n",
    "    initializer=initializer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c976d1-069b-43f7-becb-25f59c1dd672",
   "metadata": {},
   "source": [
    "### Step 2: Save the unfitted `elicit` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e2ff01-cb2a-42ec-939f-4dc7e071734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In provided directory exists already a file with identical name. Do you want to overwrite it? Press 'y' for overwriting and 'n' for abording. y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved elicit as: ./results/elicit_toy0.pkl\n"
     ]
    }
   ],
   "source": [
    "el.utils.save_elicit(elicit, \"./results/elicit_toy0.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf9da67-f47f-441a-9d8d-b05a58f1c653",
   "metadata": {},
   "source": [
    "## Load and fit the *unfitted* `elicit` object\n",
    "\n",
    "### Load the `elicit` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb297ae-7ba8-4a8a-9ef4-1987fd0a2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "elicit_toy0 = el.utils.load_elicit(\"./results/elicit_toy0.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a63228-86b4-4344-a9f0-af3b9871869a",
   "metadata": {},
   "source": [
    "### Fit the loaded `elicit` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad7e4bf1-c749-4543-901e-556fd9299d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.29it/s]\n"
     ]
    }
   ],
   "source": [
    "elicit_toy0.fit(save_dir=None, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623094aa-0085-4eae-9b8e-804e13bc805c",
   "metadata": {},
   "source": [
    "## Inspect the *fitted* `elicit` object\n",
    "+ results saved for each epoch are stored in `history` (type: dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3835528-2592-45ee-9132-cf2fd42f4a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'loss_component', 'time', 'hyperparameter', 'hyperparameter_gradient'])\n"
     ]
    }
   ],
   "source": [
    "# information saved in the history object\n",
    "print(elicit_toy0.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41287034-cab4-42cc-b6d4-49aa320f4623",
   "metadata": {},
   "source": [
    "+ results saved only for the last epoch are stored in `results` (type: dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e6faea-4ccc-4381-a809-2526bed5f037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['target_quantities', 'elicited_statistics', 'prior_samples', 'model_samples', 'model', 'loss_tensor_expert', 'loss_tensor_model', 'expert_elicited_statistics', 'expert_prior_samples', 'init_loss_list', 'init_prior', 'init_matrix'])\n"
     ]
    }
   ],
   "source": [
    "# information saved in the results object\n",
    "print(elicit_toy0.results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f77af-5c61-4271-ad55-ee42b46e928c",
   "metadata": {},
   "source": [
    "## Save results on disk\n",
    "If you want to save the results locally, you need to specify a directory name through the attribute `save_dir`. The results are then saved according to the following rule: `{save_dir_value}/{method}/{model_name}_{seed}.pkl`\n",
    "\n",
    "**Example:**\n",
    "+ consider the above created `elicit` object (\"elicit_toy0\")\n",
    "+ fit the elicit object with `save_dir=\"res\"`\n",
    "+ results are saved in `./res/parametric_prior/toy0_0.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a10e86-d9fa-47ed-8b8b-6d219cba0c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "elicit object is already fitted. Do you want to fit it again and overwrite the results? Press 'n' to stop process and 'y' to continue fitting. y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['history', 'results'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: \n",
    "# The silent argument controls whether the history is returned after fitting\n",
    "# If \"silent=True\" nothing is returned; if \"silent=False\" the history is returned.\n",
    "# by default \"silent=False\"\n",
    "hist = elicit_toy0.fit(save_dir=\"res\")\n",
    "\n",
    "final_res = pd.read_pickle(\"res/parametric_prior/toy0_0.pkl\")\n",
    "final_res.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a204aa-cb58-4526-b5de-ece360c1a6d4",
   "metadata": {},
   "source": [
    "### Save only subset of results\n",
    "Sometimes you don't want to save all possible results but only a relevant subset.\n",
    "You can control this by the arguments `save_configs_history` and `save_configs_results` in the `el.trainer` callable.\n",
    "\n",
    "**Example**\n",
    "\n",
    "I don't want to save information about the hyperparameter gradients and the single loss components.\n",
    "This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e45549-f8c8-46cb-9d3a-5a9424b2477c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'time', 'hyperparameter'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elicit = el.Elicit(\n",
    "    model=model,\n",
    "    parameters=parameters,\n",
    "    targets=targets,\n",
    "    expert=expert,\n",
    "    optimizer=optimizer,\n",
    "    trainer=el.trainer(\n",
    "        method=\"parametric_prior\",\n",
    "        name=\"toy1\",\n",
    "        seed=0,\n",
    "        epochs=4,\n",
    "        save_configs_history=el.configs.save_history(hyperparameter_gradient=False, loss_component=False)\n",
    "    ),\n",
    "    initializer=initializer\n",
    ")\n",
    "\n",
    "# fit elicit obj\n",
    "elicit.fit(save_dir=\"res\", silent=True)\n",
    "\n",
    "# inspect saved results\n",
    "# note that loss_component and hyperparameter_gradient are not saved\n",
    "pd.read_pickle(\"res/parametric_prior/toy1_0.pkl\")[\"history\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac521c67-80e8-4d00-93ba-9269791fed94",
   "metadata": {},
   "source": [
    "## Save and reload the *fitted* `elicit` object\n",
    "### Step 1: Save the fitted object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a76946a1-d67d-4014-ac18-51240caa3f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In provided directory exists already a file with identical name. Do you want to overwrite it? Press 'y' for overwriting and 'n' for abording. y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved elicit as: ./results/fit_toy0.pkl\n"
     ]
    }
   ],
   "source": [
    "el.utils.save_elicit(elicit_toy0, \"./results/fit_toy0.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807894fe-42cd-46d9-a49e-0d598bd0e9e1",
   "metadata": {},
   "source": [
    "### Step 2: Load and inspect the fitted `elicit` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4935e587-aa51-4d3e-8511-49e6b1f6e96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=10.571016>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.069366>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.578753>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.098384>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_toy0 = el.utils.load_elicit(\"./results/fit_toy0.pkl\")\n",
    "fit_toy0.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da659199-4861-46f9-bd81-4eb702c9e7ad",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "### What happens when I want to fit an already fitted `elicit` object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e4f45b-2f58-4c4a-9f0d-192df7630e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "elicit object is already fitted. Do you want to fit it again and overwrite the results? Press 'n' to stop process and 'y' to continue fitting. n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Process aborded; elicit object is not re-fitted.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_toy0.fit(save_dir=None)\n",
    "\n",
    "# prompt: \n",
    "# elicit object is already fitted. \n",
    "# Do you want to fit it again and overwrite the results? \n",
    "# Press 'n' to stop process and 'y' to continue fitting. \n",
    "\n",
    "# user input: n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28daed05-80f7-4b7e-be62-cd344231f921",
   "metadata": {},
   "source": [
    "#### Can I force re-fitting?\n",
    "Sometimes, especially when we only want to test something, it can be inconvenient to repeatedly confirm whether results should be overwritten. To address this, you can use the `force_fit` argument in the `fit` method to enable re-fitting without any prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9128e25-f9ab-4dc0-8ae3-187184503645",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_toy0.fit(save_dir=None, force_fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f95f64d-bc48-4be7-877e-c66e5c728ff9",
   "metadata": {},
   "source": [
    "### What happens when I want to save an elicit object with a name that already exists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d9908dd-a696-44b3-98f6-32f065ce69cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In provided directory exists already a file with identical name. Do you want to overwrite it? Press 'y' for overwriting and 'n' for abording. n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Process aborded. File is not overwritten.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el.utils.save_elicit(elicit_toy0, \"./results/fit_toy0.pkl\")\n",
    "\n",
    "# prompt:\n",
    "# In provided directory exists already a file with identical name. Do you want to overwrite it? \n",
    "# Press 'y' for overwriting and 'n' for abording. \n",
    "\n",
    "# user input: n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d38df-18bc-4fe2-802e-45028cb8ed8a",
   "metadata": {},
   "source": [
    "#### Can I force overwriting of file while saving?\n",
    "Sometimes, especially when we only want to test something, it can be inconvenient to repeatedly confirm whether the locally stored results file should be overwritten. To address this, you can use the `force_overwrite` argument in the `fit` method to enable re-fitting without any prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce3f09-280e-4f16-bd77-2d651f86cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "el.utils.save_elicit(elicit_toy0, \"./results/fit_toy0.pkl\", force_overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}