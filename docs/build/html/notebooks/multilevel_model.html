
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Normal Mutlilevel Model Model &#8212; Prior Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=e645c8fa"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/multilevel_model';</script>
    <link rel="icon" href="../_static/favicon-light.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/mmp-logo-light.png" class="logo__image only-light" alt="Prior Learning - Home"/>
    <script>document.write(`<img src="../_static/mmp-logo-dark.png" class="logo__image only-dark" alt="Prior Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introductory_example.html">Introductory example</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_overview.html">API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/florence-bockting/PriorLearning" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/multilevel_model.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Normal Mutlilevel Model Model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background-case-study">Background: Case Study</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-generating-model">Data generating model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-the-method">Setting up the method</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-parameters">Model parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expert-data-or-ground-truth-for-method-validation">Expert data or ground truth for method validation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-model">Generative model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#target-quantities-and-elicitation-techniques">Target quantities and elicitation techniques</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function-and-optimization-settings">Loss function and optimization settings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-learning-algorithm">Run the learning algorithm</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-model-performance">Evaluating model performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-diagnostics">Convergence diagnostics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learned-prior-distributions">Learned prior distributions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-output">Summary output</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">tfd</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span> 

<span class="kn">import</span> <span class="nn">setup.input_functions</span> <span class="k">as</span> <span class="nn">setfun</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="normal-mutlilevel-model-model">
<h1>Normal Mutlilevel Model Model<a class="headerlink" href="#normal-mutlilevel-model-model" title="Link to this heading">#</a></h1>
<section id="background-case-study">
<h2>Background: Case Study<a class="headerlink" href="#background-case-study" title="Link to this heading">#</a></h2>
<p>The accompanying example in this case study draws inspiration from the <em>sleepstudy</em> dataset (Belenky et al., 2003) that comes along with the R-package <em>lme4</em> (Bates et al., 2014). This dataset contains information about the average reaction time (RT) in milliseconds for <span class="math notranslate nohighlight">\(N\)</span> individuals who undergo sleep deprivation for nine consecutive nights (with less than three hours of sleep per night). In order to construct a model for this data, we consider a hierarchical model with days serving as a continuous predictor denoted as <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p><strong>References</strong></p>
<ul class="simple">
<li><p>Belenky, G., Wesensten, N. J., Thorne, D. R., Thomas, M. L., Sing, H. C., Redmond, D. P., … &amp; Balkin, T. J. (2003). Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: A sleep dose‐response study. <em>Journal of sleep research</em>, 12(1), 1-12.</p></li>
<li><p>Bates, D., Mächler, M., Bolker, B., &amp; Walker, S. (2015). Fitting Linear Mixed-Effects Models Using lme4. <em>Journal of Statistical Software</em>, 67, 1-48.</p></li>
</ul>
</section>
<section id="data-generating-model">
<h2>Data generating model<a class="headerlink" href="#data-generating-model" title="Link to this heading">#</a></h2>
<div class="amsmath math notranslate nohighlight" id="equation-c9c2847d-dbc9-4441-b1bd-1a1f1ee3ffbd">
<span class="eqno">(1)<a class="headerlink" href="#equation-c9c2847d-dbc9-4441-b1bd-1a1f1ee3ffbd" title="Permalink to this equation">#</a></span>\[\begin{align}
    \begin{split}
    y_{ij} &amp;= \textrm{Normal}(\theta_{ij}, s)\\
    \theta_{ij} &amp;= \beta_{0,j} + \beta_{1,j} x_{ij} \\
    \beta_{0,j} &amp;= \beta_0 + u_{0,j} \\
    \beta_{1,j} &amp;= \beta_1 + u_{1,j} \\
    ( u_{0,j}, u_{1,j} ) &amp;\sim \textrm{MvNormal}\left(\textbf{0}, \Sigma_u\right) \\
    \Sigma_u &amp;= \begin{pmatrix}\tau_0^2 &amp; \rho_{01} \tau_0 \tau_1 \\ \rho_{01} \tau_0 \tau_1 &amp; \tau_1^2\end{pmatrix} \\
    \beta_k &amp;\sim \textrm{Normal}(\mu_k, \sigma_k) \qquad\textrm{ for } k=0,1\\
    \tau_k &amp;\sim \textrm{TruncatedNormal}(0, \omega_k) \qquad\textrm{for } k=0,1\\
    \rho_{01} &amp;\sim \textrm{LKJ}(\alpha_\textrm{LKJ}) \\
    s &amp;\sim \textrm{Gamma}(\alpha, \beta).
    \end{split}
\end{align}\]</div>
<p>Here <span class="math notranslate nohighlight">\(y_{ij}\)</span> represents the average RT for the <span class="math notranslate nohighlight">\(j^{th}\)</span> participant at the <span class="math notranslate nohighlight">\(i^{th}\)</span> day with <span class="math notranslate nohighlight">\(j=1,\ldots, 200\)</span> and <span class="math notranslate nohighlight">\(i=0,\ldots,9\)</span>.
The original <em>sleepstudy</em> dataset comprises only 18 participants. However, our objective is to assess the validity of our elicitation method by recovering each model (hyper)parameter accurately. To achieve this goal and capture the precise variability indicated by the varying effects, it was necessary to employ a larger sample size.
The RT data is assumed to follow a normal distribution with local mean <span class="math notranslate nohighlight">\(\theta_{ij}\)</span> and within-person standard deviation <span class="math notranslate nohighlight">\(s\)</span>. Here, <span class="math notranslate nohighlight">\(\theta_{ij}\)</span> is predicted by a linear combination of the continuous predictor <span class="math notranslate nohighlight">\(x\)</span> with overall slope <span class="math notranslate nohighlight">\(\beta_1\)</span> and intercept <span class="math notranslate nohighlight">\(\beta_0\)</span>.
Given the potential variation in both baseline and change in RT across participants, the model incorporates varying (i.e., <em>random</em>) intercepts <span class="math notranslate nohighlight">\(u_{0,j}\)</span> and varying slopes <span class="math notranslate nohighlight">\(u_{1,j}\)</span>. These varying intercepts and slopes follow a multivariate normal distribution, centered at a mean vector of zero and with a covariance matrix <span class="math notranslate nohighlight">\(\Sigma_u\)</span>. This encodes the variability (<span class="math notranslate nohighlight">\(\tau_0, \tau_1\)</span>) and the correlation (<span class="math notranslate nohighlight">\(\rho_{01}\)</span>) between <span class="math notranslate nohighlight">\(u_{0,j}\)</span> and <span class="math notranslate nohighlight">\(u_{1,j}\)</span>.
For the resulting set of model parameters, the following prior distributions are assumed: A normal distribution for the overall (i.e., ``fixed’’) effects <span class="math notranslate nohighlight">\(\beta_k\)</span> (<span class="math notranslate nohighlight">\(k = 0, 1\)</span>) with mean <span class="math notranslate nohighlight">\(\mu_k\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma_k\)</span>. A truncated normal distribution centered at zero with a standard deviation of <span class="math notranslate nohighlight">\(\omega_k\)</span>, is employed for the person-specific variation <span class="math notranslate nohighlight">\(\tau_k\)</span>, which is constrained to be positive. The correlation parameter <span class="math notranslate nohighlight">\(\rho_{01}\)</span> follows a Lewandowski-Kurowicka-Joe distribution with scale parameter <span class="math notranslate nohighlight">\(\alpha_\textrm{LKJ}\)</span>. In the subsequent context, we set  <span class="math notranslate nohighlight">\(\alpha_\textrm{LKJ}\)</span> to 1. Additionally, a Gamma prior distribution with concentration <span class="math notranslate nohighlight">\(\alpha\)</span> and rate <span class="math notranslate nohighlight">\(\beta\)</span> is used for the within-person (error) standard deviation <span class="math notranslate nohighlight">\(s\)</span>. The goal is to learn eight hyperparameters <span class="math notranslate nohighlight">\(\lambda=(\mu_k,\sigma_k, \omega_k, \alpha, \beta)\)</span>.</p>
</section>
<section id="setting-up-the-method">
<h2>Setting up the method<a class="headerlink" href="#setting-up-the-method" title="Link to this heading">#</a></h2>
<section id="model-parameters">
<h3>Model parameters<a class="headerlink" href="#model-parameters" title="Link to this heading">#</a></h3>
<p>First, we need to specify the parameters in the generative model using the <code class="docutils literal notranslate"><span class="pre">param()</span></code> function which requires the following input:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: the name of the model parameter</p>
<ul>
<li><p>In our model we have five parameters which we will denote as <em>b0</em> (fixed-effect; intercept), <em>b1</em> (fixed-effect; slope), <em>tau0</em> (random-intercept), <em>tau1</em> (random-slope), <em>sigma</em> (within-participant variation)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">family</span></code>: the prior distribution family</p>
<ul>
<li><p>We assume a Normal prior distribution for the fixed effects, a truncated normal for the random effects and a gamma distribution for the random noise parameter.</p></li>
<li><p>We created a wrapper around all of these distributions, in order to learn all hyperparameter on the log-scale.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">hyperparams_dict</span></code>: a dictionary including the name of the hyperparameter values and the initial value for the learning algorithm</p>
<ul>
<li><p>We use distributions from which an initial value is drawn.</p></li>
<li><p>When a hyperparameter is learned on the log-scale, we indicate this by writing “log_” before the actual name of the hyperparameter, such as <em>log_sigma0</em>.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">user_input.custom_functions</span> <span class="kn">import</span> <span class="n">Normal_log_log</span>
<span class="kn">from</span> <span class="nn">user_input.custom_functions</span> <span class="kn">import</span> <span class="n">Gamma_log</span>
<span class="kn">from</span> <span class="nn">user_input.custom_functions</span> <span class="kn">import</span> <span class="n">TruncNormal_log</span>

<span class="n">normal_log</span> <span class="o">=</span> <span class="n">Normal_log_log</span><span class="p">()</span>
<span class="n">normal_trunc_log</span> <span class="o">=</span> <span class="n">TruncNormal_log</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">500.</span><span class="p">)</span>
<span class="n">gamma_log</span> <span class="o">=</span> <span class="n">Gamma_log</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">model_params</span><span class="p">():</span>  
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;b0&quot;</span><span class="p">,</span>
              <span class="n">family</span> <span class="o">=</span> <span class="n">normal_log</span><span class="p">,</span> 
              <span class="n">hyperparams_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;log_mu0&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">5.</span><span class="p">,</span><span class="mf">2.</span><span class="p">),</span> 
                                  <span class="s2">&quot;log_sigma0&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)}),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;b1&quot;</span><span class="p">,</span>
              <span class="n">family</span> <span class="o">=</span> <span class="n">normal_log</span><span class="p">,</span> 
              <span class="n">hyperparams_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;log_mu1&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span><span class="mf">2.</span><span class="p">),</span> 
                                  <span class="s2">&quot;log_sigma1&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)}),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;tau0&quot;</span><span class="p">,</span>
              <span class="n">family</span> <span class="o">=</span> <span class="n">normal_trunc_log</span><span class="p">,</span> 
              <span class="n">hyperparams_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;log_omega0&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)}),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;tau1&quot;</span><span class="p">,</span>
              <span class="n">family</span> <span class="o">=</span> <span class="n">normal_trunc_log</span><span class="p">,</span> 
              <span class="n">hyperparams_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;log_omega1&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)}),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;sigma&quot;</span><span class="p">,</span>
              <span class="n">family</span> <span class="o">=</span> <span class="n">gamma_log</span><span class="p">,</span> 
              <span class="n">hyperparams_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;log_concentration&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">5.</span><span class="p">,</span><span class="mf">0.5</span><span class="p">),</span> 
                                  <span class="s2">&quot;log_rate&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)})</span>
             <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="expert-data-or-ground-truth-for-method-validation">
<h3>Expert data or ground truth for method validation<a class="headerlink" href="#expert-data-or-ground-truth-for-method-validation" title="Link to this heading">#</a></h3>
<p>Next, we define the <code class="docutils literal notranslate"><span class="pre">expert()</span></code> function which represents the data input based on which the method has to learn.
This can be either</p>
<ul class="simple">
<li><p>data from an expert (in this case the argument <code class="docutils literal notranslate"><span class="pre">data</span></code> expects a string with the location to the expert data) or</p></li>
<li><p>an expected ground truth in which case we simulate once from the method using a pre-defined hyperparameter vector <span class="math notranslate nohighlight">\(\lambda^*\)</span> and learn then on this simulated data (in this case we need to set the argument <code class="docutils literal notranslate"><span class="pre">simulate_data</span> <span class="pre">=</span> <span class="pre">True</span></code> and specify the true hyperparameter values in <code class="docutils literal notranslate"><span class="pre">simulator_specs</span></code>.</p></li>
</ul>
<p>The second approach is helpful when we want to validate our method and check whether the implementation is correct. Because it allows us to check whether we can recover an expected ground truth under <em>ideal circumstances</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">expert_input</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">setfun</span><span class="o">.</span><span class="n">expert</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                  <span class="n">simulate_data</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                  <span class="n">simulator_specs</span> <span class="o">=</span> <span class="p">{</span>
                      <span class="s2">&quot;b0&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">250.4</span><span class="p">,</span> <span class="mf">7.27</span><span class="p">),</span>
                      <span class="s2">&quot;b1&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">30.26</span><span class="p">,</span> <span class="mf">4.82</span><span class="p">),</span>
                      <span class="s2">&quot;tau0&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">33.</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">500</span><span class="p">),</span>
                      <span class="s2">&quot;tau1&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">23.</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">500</span><span class="p">),</span>
                      <span class="s2">&quot;sigma&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="mf">200.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">)</span>
                      <span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="generative-model">
<h3>Generative model<a class="headerlink" href="#generative-model" title="Link to this heading">#</a></h3>
<p>Now, we can define our generative model from which data should be simulated. We specified the model already formally.
For implementation purposes a particular <em>input-output</em> structure is required:</p>
<ul class="simple">
<li><p>input:</p>
<ul>
<li><p>(required) <code class="docutils literal notranslate"><span class="pre">prior_samples</span></code>: samples drawn from the prior distributions</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">design_matrix</span></code>: design matrix used for the regression model</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">selected_days</span></code>: days for which expert should be queried</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">alpha_lkj</span></code>: parameter of the LKJ prior on the correlation which will be fixed to 1.</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">N_subj</span></code>: number of participants</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">N_days</span></code>: number of days (selected days for elicitation)</p></li>
</ul>
</li>
<li><p>output:</p>
<ul>
<li><p>(required) <code class="docutils literal notranslate"><span class="pre">likelihood</span></code>: model likelihood</p></li>
<li><p>(required) <code class="docutils literal notranslate"><span class="pre">ypred</span></code>: prior predictions (if likelihood is discrete <code class="docutils literal notranslate"><span class="pre">ypred=None</span></code> as it will be approximated using the Softmax-Gumble method)</p></li>
<li><p>(required) <code class="docutils literal notranslate"><span class="pre">epred</span></code>: linear predictor</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">prior_samples</span></code>: we use it here again as output for easier follow-up computations</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">meanperday</span></code>: distribution of mean reaction time per selected day</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">R2day0</span></code>: R2 for day 0 (incl. only variation of the random intercept (individual differences in RT without considering the treatment)</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">R2day9</span></code>: R2 for day 9 (incl. variation of the random intercept and slope (individual differences in RT considering treatment effect)</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">mu0sdcomp</span></code>:  standard deviation of linear predictor at day 0</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">mu9sdcomp</span></code>:  standard deviation of linear predictor at day 9</p></li>
<li><p>(optional) <code class="docutils literal notranslate"><span class="pre">sigma</span></code>: random noise parameter</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GenerativeMultilevelModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                <span class="n">prior_samples</span><span class="p">,</span>        
                <span class="n">design_matrix</span><span class="p">,</span> 
                <span class="n">selected_days</span><span class="p">,</span>
                <span class="n">alpha_lkj</span><span class="p">,</span>
                <span class="n">N_subj</span><span class="p">,</span>
                <span class="n">N_days</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span>        
                <span class="p">):</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="n">prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># correlation matrix</span>
        <span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">LKJ</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha_lkj</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="n">rep</span><span class="p">))</span>
        
        <span class="c1"># SD matrix</span>
        <span class="c1"># shape = (B, 2)</span>
        <span class="n">taus</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="p">),</span> 
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># shape = (B, 2, 2)</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">taus</span><span class="p">)</span>
        
        <span class="c1"># covariance matrix: Cov=S*R*S</span>
        <span class="c1"># shape = (B, 2, 2)</span>
        <span class="n">corr_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">diagonal</span><span class="o">=</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">),</span> 
                                  <span class="n">padding_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">))</span>
        <span class="c1"># compute cov matrix</span>
        <span class="c1"># shape = (B, 2, 2)</span>
        <span class="n">cov_mx_subj</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">S</span><span class="p">,</span><span class="n">corr_mat</span><span class="p">),</span> <span class="n">S</span><span class="p">)</span>
        
        <span class="c1"># generate by-subject random effects: T0s, T1s</span>
        <span class="c1"># shape = (B, N_subj, 2)</span>
        <span class="n">subj_rfx</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
            <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span>
                <span class="n">loc</span><span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> 
                <span class="n">scale_tril</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">cov_mx_subj</span><span class="p">)),</span> 
            <span class="n">N_subj</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        
        <span class="c1"># broadcast by-subject random effects</span>
        <span class="c1"># shape = (B, N_obs, 2) with N_obs = N_subj*N_days</span>
        <span class="n">taus</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">subj_rfx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> 
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N_subj</span><span class="p">,</span> <span class="n">N_days</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> 
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N_subj</span><span class="o">*</span><span class="n">N_days</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        
        <span class="c1"># reshape coefficients</span>
        <span class="c1"># shape = (B, rep, N_obs, 2) with N_obs = N_subj*N_days</span>
        <span class="n">betas_reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> 
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">rep</span><span class="p">,</span> <span class="n">N_subj</span><span class="o">*</span><span class="n">N_days</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        
        <span class="c1">## compute betas_s</span>
        <span class="c1"># shape = (B, rep, N_obs, 2) with N_obs = N_subj*N_days</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">betas_reshaped</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">taus</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> 
        
        <span class="c1"># compute linear predictor term</span>
        <span class="c1"># shape = (B, rep, N_obs) with N_obs = N_subj*N_days</span>
        <span class="n">epred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">betas</span><span class="p">[:,:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">design_matrix</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> 
                       <span class="n">betas</span><span class="p">[:,:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">design_matrix</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
        
        <span class="c1"># define likelihood</span>
        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="n">epred</span><span class="p">,</span>
                                <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">[:,:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                                <span class="p">)</span>
        
        <span class="c1"># sample prior predictive data</span>
        <span class="n">ypred</span> <span class="o">=</span> <span class="n">likelihood</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        
        <span class="c1"># custom target quantities </span>
        <span class="c1">## epred averaged over individuals</span>
        <span class="n">epred_days</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">epred</span><span class="p">[:,:,</span><span class="n">i</span><span class="p">::</span><span class="n">N_days</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_days</span><span class="p">)],</span> 
                              <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mean_per_day</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">epred_days</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># R2 for initial day</span>
        <span class="n">R2_day0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_variance</span><span class="p">(</span><span class="n">epred</span><span class="p">[:,:,</span><span class="n">selected_days</span><span class="p">[</span><span class="mi">0</span><span class="p">]::</span><span class="n">N_days</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                            <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_variance</span><span class="p">(</span><span class="n">ypred</span><span class="p">[:,:,</span><span class="n">selected_days</span><span class="p">[</span><span class="mi">0</span><span class="p">]::</span><span class="n">N_days</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># R2 for last day</span>
        <span class="n">R2_day9</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_variance</span><span class="p">(</span><span class="n">epred</span><span class="p">[:,:,</span><span class="n">selected_days</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]::</span><span class="n">N_days</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                            <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_variance</span><span class="p">(</span><span class="n">ypred</span><span class="p">[:,:,</span><span class="n">selected_days</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]::</span><span class="n">N_days</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># compute standard deviation of linear predictor </span>
        <span class="n">mu0_sd_comp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">epred</span><span class="p">[:,:,</span><span class="n">selected_days</span><span class="p">[</span><span class="mi">0</span><span class="p">]::</span><span class="n">N_days</span><span class="p">],</span> 
                                         <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mu9_sd_comp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">epred</span><span class="p">[:,:,</span><span class="n">selected_days</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]::</span><span class="n">N_days</span><span class="p">],</span> 
                                         <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">,</span>     
                    <span class="n">ypred</span> <span class="o">=</span> <span class="n">ypred</span><span class="p">,</span>   
                    <span class="n">epred</span> <span class="o">=</span> <span class="n">epred</span><span class="p">,</span>
                    <span class="n">prior_samples</span> <span class="o">=</span> <span class="n">prior_samples</span><span class="p">,</span>
                    <span class="n">meanperday</span> <span class="o">=</span> <span class="n">mean_per_day</span><span class="p">,</span>
                    <span class="n">R2day0</span> <span class="o">=</span> <span class="n">R2_day0</span><span class="p">,</span>
                    <span class="n">R2day9</span> <span class="o">=</span> <span class="n">R2_day9</span><span class="p">,</span>
                    <span class="n">mu0sdcomp</span> <span class="o">=</span> <span class="n">mu0_sd_comp</span><span class="p">,</span>
                    <span class="n">mu9sdcomp</span> <span class="o">=</span> <span class="n">mu9_sd_comp</span><span class="p">,</span>
                    <span class="n">sigma</span> <span class="o">=</span> <span class="n">prior_samples</span><span class="p">[:,:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>After having specified the generative model, we load all information into the <code class="docutils literal notranslate"><span class="pre">model()</span></code> function which requires the following specifications:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">generative_model</span></code>: the class of the generative model (callable)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">additional_model_args</span></code>: specifications of model arguments used as input that are not prior samples</p>
<ul>
<li><p>in this example we have the additional arguments: <em>design_matrix</em> and <em>total_count</em>. The key name must match with the argument name in the generative model.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">discrete_likelihood</span></code>: whether likelihood is discrete or not; if <em>True</em> the softmax-gumble method will be used in order to approximate <code class="docutils literal notranslate"><span class="pre">ypred</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">user_input.generative_models</span> <span class="kn">import</span> <span class="n">GenerativeMultilevelModel</span>
<span class="kn">from</span> <span class="nn">user_input.design_matrices</span> <span class="kn">import</span> <span class="n">load_design_matrix_sleep</span>

<span class="n">design_matrix</span> <span class="o">=</span> <span class="n">load_design_matrix_sleep</span><span class="p">(</span><span class="s2">&quot;divide_by_std&quot;</span><span class="p">,</span> <span class="n">N_days</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
                                         <span class="n">N_subj</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> 
                                         <span class="n">selected_days</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">9</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">generative_model</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">setfun</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">GenerativeMultilevelModel</span><span class="p">,</span>
                 <span class="n">additional_model_args</span> <span class="o">=</span> <span class="p">{</span>
                     <span class="s2">&quot;design_matrix&quot;</span><span class="p">:</span> <span class="n">design_matrix</span><span class="p">,</span>
                     <span class="s2">&quot;selected_days&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">9</span><span class="p">],</span>
                     <span class="s2">&quot;alpha_lkj&quot;</span><span class="p">:</span> <span class="mf">1.</span><span class="p">,</span>
                     <span class="s2">&quot;N_subj&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
                     <span class="s2">&quot;N_days&quot;</span><span class="p">:</span> <span class="mi">5</span>
                     <span class="p">},</span>
                 <span class="n">discrete_likelihood</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="target-quantities-and-elicitation-techniques">
<h3>Target quantities and elicitation techniques<a class="headerlink" href="#target-quantities-and-elicitation-techniques" title="Link to this heading">#</a></h3>
<p>In the next step, we can define the target quantities and the corresponding elicitation technique. Both is specified through the <code class="docutils literal notranslate"><span class="pre">target()</span></code> function which has the following options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: name of the target quantity</p>
<ul>
<li><p>if you want to use a target quantity which is already specified in the generative model, then you the value for <code class="docutils literal notranslate"><span class="pre">name</span></code> must match with the output argument from the generative model. For this example, <code class="docutils literal notranslate"><span class="pre">ypred</span></code> is taken directly from the generative model.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">custom_target_function</span></code>: (optional) it is possible to compute custom target quantities from the output of the generative model. Here we compute for example the group means based on the prior predictions. If a custom target function is used the following specifications have to be done:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">function</span></code>: the respective custom function (callable)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">additional_args</span></code>: in case the custom function takes as arguments parameters that are not in the output of the generative model, these parameters need to be specified here in form of a dictionary. The argument name is used as key and the respective value.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">elicitation_method</span></code>: currently available elicitation methods are <em>histogram</em>, <em>moments</em>, and <em>quantiles</em></p>
<ul>
<li><p>some of the elicitation methods require additional specifications:</p>
<ul>
<li><p><em>moments</em> requires the additional argument <code class="docutils literal notranslate"><span class="pre">moments_specs</span></code> which takes a tuple with the moments that should be elicited e.g. (“mean”, “sd”)</p></li>
<li><p><em>quantiles</em> requires the additional argument <code class="docutils literal notranslate"><span class="pre">quantiles_specs</span></code> which takes a tuple with the percentages that should be elicited e.g. (25, 50, 75)</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">loss_components</span></code>: specifies the form of the loss components. Possible values are <em>by-group</em>, <em>by-stats</em>,<em>all</em>. (Detailed description will follow)</p></li>
</ul>
<p>In this specific case the implementation is not so currently not so straightforward but will be improved in future.
The target quantities for this model are as follows:</p>
<ul class="simple">
<li><p><em>sigma</em>: the within-participant variation (elicitation in the parameter space)</p></li>
<li><p><em>meanperday</em>: the distribution of mean reaction time per selected day</p></li>
<li><p><em>R2-day0</em>: the variance explained (without considering the treatment effect)</p></li>
<li><p><em>R2-day9</em>: the variance explained (considering the treatment effect</p></li>
</ul>
<p>Furthermore, we consider the following definition of <span class="math notranslate nohighlight">\(R^2 = \frac{\text{Var}(\mu)}{\text{Var}(y_{pred})}\)</span> with <span class="math notranslate nohighlight">\(\mu\)</span> being the linear predictor.
Then the following holds <span class="math notranslate nohighlight">\(\text{SD}(\mu) = \sqrt{R^2 \cdot \text{Var}(y_{pred})}\)</span>.
During our simulation studies, we observed that the learning of random effects is improved when we use <span class="math notranslate nohighlight">\(\text{SD}(\mu)\)</span> as a loss component instead of <span class="math notranslate nohighlight">\(R^2\)</span>. That being said, the target quantity queried from an expert would remain <span class="math notranslate nohighlight">\(R^2\)</span>, but it would be internally transformed, and learning would take place on this transformed value. Therefore, we have two different sets of target quantities.</p>
<ul class="simple">
<li><p>Set 1: Defines the target quantities for the ground truth elicited statistics, whereby <span class="math notranslate nohighlight">\(\text{SD}(\mu)\)</span> is used from the simulated data.</p></li>
<li><p>Set 2: Defines the target quantities for the model simulations whereby we use a custom function which takes as input <span class="math notranslate nohighlight">\(R^2\)</span> from the <em>oracle</em> (aka expert or here ground truth), uses for <span class="math notranslate nohighlight">\(text{Var}(y_{pred})\)</span> the simulated data and returns the respective simulated <span class="math notranslate nohighlight">\(\text{SD}(\mu)\)</span>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">user_input.custom_functions</span> <span class="kn">import</span> <span class="n">custom_mu0_sd</span><span class="p">,</span> <span class="n">custom_mu9_sd</span>
<span class="kn">from</span> <span class="nn">setup.create_dictionaries</span> <span class="kn">import</span> <span class="n">create_dict</span>

<span class="nd">@create_dict</span>
<span class="k">def</span> <span class="nf">target_quantities1</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;ground_truth&quot;</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;sigma&quot;</span><span class="p">,</span>
                <span class="n">elicitation_method</span> <span class="o">=</span> <span class="s2">&quot;moments&quot;</span><span class="p">,</span>
                <span class="n">moments_specs</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span><span class="s2">&quot;sd&quot;</span><span class="p">),</span>
                <span class="n">loss_components</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>
                <span class="p">),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;mu0sdcomp&quot;</span><span class="p">,</span>
                <span class="n">elicitation_method</span> <span class="o">=</span> <span class="s2">&quot;histogram&quot;</span><span class="p">,</span>
                <span class="n">loss_components</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>
                <span class="p">),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;mu9sdcomp&quot;</span><span class="p">,</span>
                <span class="n">elicitation_method</span> <span class="o">=</span> <span class="s2">&quot;histogram&quot;</span><span class="p">,</span>
                <span class="n">loss_components</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>
                <span class="p">),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;meanperday&quot;</span><span class="p">,</span>
                <span class="n">elicitation_method</span> <span class="o">=</span> <span class="s2">&quot;quantiles&quot;</span><span class="p">,</span>
                <span class="n">quantiles_specs</span> <span class="o">=</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">),</span>
                <span class="n">loss_components</span> <span class="o">=</span> <span class="s2">&quot;by-group&quot;</span>
                <span class="p">)</span>
        <span class="p">)</span>

<span class="nd">@create_dict</span>
<span class="k">def</span> <span class="nf">target_quantities2</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;learning&quot;</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;sigma&quot;</span><span class="p">,</span>
                <span class="n">elicitation_method</span> <span class="o">=</span> <span class="s2">&quot;moments&quot;</span><span class="p">,</span>
                <span class="n">moments_specs</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span><span class="s2">&quot;sd&quot;</span><span class="p">),</span>
                <span class="n">loss_components</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>
                <span class="p">),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;mu0sdcomp&quot;</span><span class="p">,</span>
                <span class="n">elicitation_method</span> <span class="o">=</span> <span class="s2">&quot;histogram&quot;</span><span class="p">,</span>
                <span class="n">loss_components</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span>
                <span class="n">custom_target_function</span><span class="o">=</span><span class="p">{</span>
                                    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">custom_mu0_sd</span><span class="p">,</span>
                                    <span class="s2">&quot;additional_args&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;selected_days&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">9</span><span class="p">]}</span>
                                    <span class="p">}</span>
                <span class="p">),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;mu9sdcomp&quot;</span><span class="p">,</span>
                <span class="n">elicitation_method</span> <span class="o">=</span> <span class="s2">&quot;histogram&quot;</span><span class="p">,</span>
                <span class="n">loss_components</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span>
                <span class="n">custom_target_function</span><span class="o">=</span><span class="p">{</span>
                                    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">custom_mu9_sd</span><span class="p">,</span>
                                    <span class="s2">&quot;additional_args&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;selected_days&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">9</span><span class="p">]}</span>
                                    <span class="p">}</span>
                <span class="p">),</span>
        <span class="n">setfun</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;meanperday&quot;</span><span class="p">,</span>
                <span class="n">elicitation_method</span> <span class="o">=</span> <span class="s2">&quot;quantiles&quot;</span><span class="p">,</span>
                <span class="n">quantiles_specs</span> <span class="o">=</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">),</span>
                <span class="n">loss_components</span> <span class="o">=</span> <span class="s2">&quot;by-group&quot;</span>
                <span class="p">)</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="loss-function-and-optimization-settings">
<h3>Loss function and optimization settings<a class="headerlink" href="#loss-function-and-optimization-settings" title="Link to this heading">#</a></h3>
<p>The loss function used to compute the discrepancy between the expert and the model-implied elicited statistics is specified via the <code class="docutils literal notranslate"><span class="pre">loss()</span></code> function which has the following arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">loss_function</span></code>: the discrepancy measure (string: <em>mmd-energy</em> or callable)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">loss_weighting</span></code>: if a weighting scheme for the multiobjective loss function should be used.</p></li>
</ul>
<p>For the optimization settings, we consider for the moment only batch stochastic gradient descent for which we need to specify the optimizer using the <code class="docutils literal notranslate"><span class="pre">optimization()</span></code> function, which takes two arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">optimizer</span></code>: The optimizer that should be used for the current case study (here we use the Adam optimizer)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizer_specs</span></code>: If further specifications of the optimizer are needed, they are specified here. For the Adam optimizer we need for example an initial learning rate. The additional keyword arguments are specified in form of a dictionary with the key matching the argument name. In this case study we use a cosine decay learning rate schedule with restarts. And we clip the gradient norm at 1.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functions.loss_functions</span> <span class="kn">import</span> <span class="n">MMD_energy</span>

<span class="k">def</span> <span class="nf">loss_function</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">setfun</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">MMD_energy</span><span class="p">,</span>
                <span class="n">loss_weighting</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="p">)</span>

<span class="c1">#%% Training settings</span>
<span class="k">def</span> <span class="nf">optimization_settings</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">setfun</span><span class="o">.</span><span class="n">optimization</span><span class="p">(</span>
                    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
                    <span class="n">optimizer_specs</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">CosineDecayRestarts</span><span class="p">(</span>
                            <span class="mf">0.005</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
                        <span class="s2">&quot;clipnorm&quot;</span><span class="p">:</span> <span class="mf">1.0</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-the-learning-algorithm">
<h3>Run the learning algorithm<a class="headerlink" href="#run-the-learning-algorithm" title="Link to this heading">#</a></h3>
<p>Finally we can wrap everything up and run the learning algorithm. Therefore we specify the last hyperparameter needed by the learning algorithm with the following <code class="docutils literal notranslate"><span class="pre">prior_elicitation()</span></code> function:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">method</span></code>: method for learning the prior distributions (currently available: <em>parametric_prior</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sim_id</span></code>: unique name of model (also used for saving results)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">B</span></code>: batch size</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rep</span></code>: number of simulations from the prior distributions</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">seed</span></code>: seed for the current simulation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">burnin</span></code>: runs before learning starts in order to find good initial values (if drawn randomly)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epochs</span></code>: number of learning cycles until learning stops</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">output_path</span></code>: file location for storing results</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">setfun</span><span class="o">.</span><span class="n">prior_elicitation</span><span class="p">(</span>
    <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;parametric_prior&quot;</span><span class="p">,</span>
    <span class="n">sim_id</span> <span class="o">=</span> <span class="s2">&quot;mlm_34765522&quot;</span><span class="p">,</span>
    <span class="n">B</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
    <span class="n">rep</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">34765522</span><span class="p">,</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">700</span><span class="p">,</span>
    <span class="n">output_path</span> <span class="o">=</span> <span class="s2">&quot;results&quot;</span><span class="p">,</span>
    <span class="n">burnin</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">model_params</span> <span class="o">=</span> <span class="n">model_params</span><span class="p">,</span>
    <span class="n">expert_input</span> <span class="o">=</span> <span class="n">expert_input</span><span class="p">,</span>
    <span class="n">generative_model</span> <span class="o">=</span> <span class="n">generative_model</span><span class="p">,</span>
    <span class="n">target_quantities</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_quantities1</span><span class="p">,</span><span class="n">target_quantities2</span><span class="p">),</span>
    <span class="n">loss_function</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">,</span>
    <span class="n">optimization_settings</span> <span class="o">=</span> <span class="n">optimization_settings</span><span class="p">,</span>
    <span class="n">log_info</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">view_ep</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">print_info</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="evaluating-model-performance">
<h2>Evaluating model performance<a class="headerlink" href="#evaluating-model-performance" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">validation.plotting</span> <span class="k">as</span> <span class="nn">vp</span> 
<span class="kn">from</span> <span class="nn">vp.plot_learned_prior</span> <span class="kn">import</span> <span class="n">learned_prior_multilevel</span>
<span class="kn">from</span> <span class="nn">vp.plot_diagnostics</span> <span class="kn">import</span> <span class="n">diagnostics_multilevel</span>

<span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;../sim_results/&quot;</span>
<span class="n">file</span> <span class="o">=</span> <span class="s2">&quot;mlm_34765522&quot;</span>
<span class="n">true_values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">250.4</span><span class="p">,</span> <span class="mf">7.27</span><span class="p">,</span> <span class="mf">30.26</span><span class="p">,</span> <span class="mf">4.82</span><span class="p">,</span> <span class="mf">33.</span><span class="p">,</span> <span class="mf">23.</span><span class="p">,</span> <span class="mf">200.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]</span>
<span class="n">selected_obs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">9</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<section id="convergence-diagnostics">
<h3>Convergence diagnostics<a class="headerlink" href="#convergence-diagnostics" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot diagnostics</span>
<span class="n">diagnostics_multilevel</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file</span><span class="p">,</span> <span class="n">save_fig</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/21f5409d8368a0131133269ce9a0736c67782b660db5a304b677163aae262931.png" src="../_images/21f5409d8368a0131133269ce9a0736c67782b660db5a304b677163aae262931.png" />
</div>
</div>
</section>
<section id="learned-prior-distributions">
<h3>Learned prior distributions<a class="headerlink" href="#learned-prior-distributions" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learned_prior_multilevel</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file</span><span class="p">,</span> <span class="n">selected_obs</span><span class="p">,</span> <span class="n">true_values</span><span class="p">,</span> <span class="n">last_vals</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> 
                          <span class="n">save_fig</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/8f51d7cd269e35cbaeb61ed01473c3063c39d95a91dc5b2b255b721896b15d90.png" src="../_images/8f51d7cd269e35cbaeb61ed01473c3063c39d95a91dc5b2b255b721896b15d90.png" />
</div>
</div>
</section>
<section id="summary-output">
<h3>Summary output<a class="headerlink" href="#summary-output" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">setup.write_results</span> <span class="kn">import</span> <span class="n">model_summary</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># get global dictionary</span>
<span class="n">global_dict</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="n">path</span><span class="o">+</span><span class="n">file</span><span class="o">+</span><span class="s2">&quot;/global_dict.pkl&quot;</span><span class="p">)</span>

<span class="c1"># print summary of method specifications</span>
<span class="n">model_summary</span><span class="p">(</span><span class="n">path</span><span class="o">+</span><span class="n">file</span><span class="p">,</span> <span class="n">global_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>General summary
---------------- 
method=parametric_prior
sim_id=mlm_34765535
seed=34765522
B=128
rep=200
epochs=700
wall time=54:34 (min:sec)
optimizer=&lt;class &#39;keras.src.optimizers.adam.Adam&#39;&gt;
learning rate={&#39;lr_scheduler&#39;: &lt;keras.src.optimizers.schedules.learning_rate_schedule.CosineDecayRestarts object at 0x000001ED78D22340&gt;, &#39;init_lr&#39;: 0.005, &#39;decay_steps&#39;: 100}

Model info
---------------- 
model name=&lt;class &#39;user_input.generative_models.GenerativeMultilevelModel&#39;&gt;
model parameters=[&#39;b0&#39;, &#39;b1&#39;, &#39;tau0&#39;, &#39;tau1&#39;, &#39;sigma&#39;]

Parametric Prior
---------------- 
distribution family={&#39;b0&#39;: &#39;Normal_log&#39;, &#39;b1&#39;: &#39;Normal_log&#39;, &#39;tau0&#39;: &#39;TruncatedNormal_log&#39;, &#39;tau1&#39;: &#39;TruncatedNormal_log&#39;, &#39;sigma&#39;: &#39;Gamma_log&#39;}
initialization={&#39;log_mu0&#39;: {&#39;loc&#39;: 5.0, &#39;scale&#39;: 2.0, &#39;name&#39;: &#39;Normal&#39;}, &#39;log_sigma0&#39;: {&#39;loc&#39;: 2.0, &#39;scale&#39;: 0.5, &#39;name&#39;: &#39;Normal&#39;}, &#39;log_mu1&#39;: {&#39;loc&#39;: 3.0, &#39;scale&#39;: 2.0, &#39;name&#39;: &#39;Normal&#39;}, &#39;log_sigma1&#39;: {&#39;loc&#39;: 1.5, &#39;scale&#39;: 0.5, &#39;name&#39;: &#39;Normal&#39;}, &#39;log_omega0&#39;: {&#39;loc&#39;: 3.0, &#39;scale&#39;: 0.5, &#39;name&#39;: &#39;Normal&#39;}, &#39;log_omega1&#39;: {&#39;loc&#39;: 3.0, &#39;scale&#39;: 0.5, &#39;name&#39;: &#39;Normal&#39;}, &#39;log_concentration&#39;: {&#39;loc&#39;: 5.0, &#39;scale&#39;: 0.5, &#39;name&#39;: &#39;Normal&#39;}, &#39;log_rate&#39;: {&#39;loc&#39;: 2.0, &#39;scale&#39;: 0.5, &#39;name&#39;: &#39;Normal&#39;}}

Target quantities and elicitation techniques
--------------------- 

expert:
===== 
  target quantities elicitation technique combine-loss
0             sigma               moments          all
1         mu0sdcomp             histogram          all
2         mu9sdcomp             histogram          all
3        meanperday             quantiles     by-group
learning:
===== 
  target quantities elicitation technique combine-loss
0             sigma               moments          all
1         mu0sdcomp             histogram          all
2         mu9sdcomp             histogram          all
3        meanperday             quantiles     by-group


Loss components
--------------------- 

               loss components       shape
0      moments.mean_sigma_loss    [128, 1]
1        moments.sd_sigma_loss    [128, 1]
2   histogram_mu0sdcomp_loss_1  [128, 200]
3   histogram_mu9sdcomp_loss_2  [128, 200]
4  quantiles_meanperday_loss_0    [128, 3]
5  quantiles_meanperday_loss_1    [128, 3]
6  quantiles_meanperday_loss_2    [128, 3]
7  quantiles_meanperday_loss_3    [128, 3]
8  quantiles_meanperday_loss_4    [128, 3]
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background-case-study">Background: Case Study</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-generating-model">Data generating model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-the-method">Setting up the method</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-parameters">Model parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expert-data-or-ground-truth-for-method-validation">Expert data or ground truth for method validation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-model">Generative model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#target-quantities-and-elicitation-techniques">Target quantities and elicitation techniques</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function-and-optimization-settings">Loss function and optimization settings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-learning-algorithm">Run the learning algorithm</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-model-performance">Evaluating model performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-diagnostics">Convergence diagnostics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learned-prior-distributions">Learned prior distributions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-output">Summary output</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Florence Bockting
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Florence Bockting.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>